{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":94771,"databundleVersionId":13044405,"isSourceIdPinned":false,"sourceType":"competition"}],"dockerImageVersionId":31090,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"4d3868ee-c866-4ac0-a7f9-bd6be1914e03","cell_type":"markdown","source":"# MITSUI&CO. Commodity Prediction Challenge","metadata":{}},{"id":"a37737e0-2fd8-4a01-ad92-5b7d7193f0bf","cell_type":"markdown","source":"- Implementing a baseline XGBoost model to predict commodity return differences.\n- The goal is to maximize the rank correlation Sharpe ratio.","metadata":{}},{"id":"21fd4c19-71f9-4e45-bd15-6c6841e1b64b","cell_type":"code","source":"# !pip install xgboost pandas numpy scikit-learn matplotlib seaborn polars optuna","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T09:22:37.004849Z","iopub.execute_input":"2025-08-30T09:22:37.005575Z","iopub.status.idle":"2025-08-30T09:22:37.009425Z","shell.execute_reply.started":"2025-08-30T09:22:37.005530Z","shell.execute_reply":"2025-08-30T09:22:37.008745Z"}},"outputs":[],"execution_count":2},{"id":"49c747ee-0414-4caa-8dd9-1dac9d4f104b","cell_type":"code","source":"# Imports\nimport os\nimport time\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm import tqdm\nimport polars as pl\nimport xgboost as xgb\nfrom sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import make_scorer\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'polars'","output_type":"error","traceback":["\u001b[31m---------------------------------------------------------------------------\u001b[39m","\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)","\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtqdm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpolars\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpl\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mxgboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mxgb\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TimeSeriesSplit, RandomizedSearchCV\n","\u001b[31mModuleNotFoundError\u001b[39m: No module named 'polars'"]}],"execution_count":2},{"id":"7020c418-9cdd-422f-bcd7-b533e96cca34","cell_type":"code","source":"# Set device\ntry:\n    xgb_gpu_test = xgb.XGBRegressor(tree_method='gpu_hist')\n    xgb_gpu_test.fit(np.array([[1,2], [3,4]]), np.array([1,2]))\n    GPU_AVAILABLE = True\n    print(\"GPU is available for XGBoost training\")\nexcept:\n    GPU_AVAILABLE = False\n    print(\"GPU not available, using CPU for XGBoost\")","metadata":{},"outputs":[],"execution_count":null},{"id":"52c147a3-0154-4983-8d9b-892510d6c109","cell_type":"markdown","source":"### Evaluation Metric Implementation","metadata":{}},{"id":"346bea7c-6ef1-401f-a403-ab4de9265429","cell_type":"code","source":"# Define function to compute evaluation metric\nSOLUTION_NULL_FILLER = -999999\n\ndef rank_correlation_sharpe_ratio(merged_df: pd.DataFrame) -> float:\n    prediction_cols = [col for col in merged_df.columns if col.startswith('prediction_')]\n    target_cols = [col for col in merged_df.columns if col.startswith('target_')]\n\n    def _compute_rank_correlation(row):\n        non_null_targets = [col for col in target_cols if not pd.isnull(row[col])]\n        matching_predictions = [col for col in prediction_cols if col.replace('prediction', 'target') in non_null_targets]\n        if not non_null_targets:\n            return 0.0  # Return 0 instead of raising error for robustness\n        if row[non_null_targets].std(ddof=0) == 0 or row[matching_predictions].std(ddof=0) == 0:\n            return 0.0  # Return 0 instead of raising error for robustness\n        return np.corrcoef(row[matching_predictions].rank(method='average'), \n                          row[non_null_targets].rank(method='average'))[0, 1]\n\n    daily_rank_corrs = merged_df.apply(_compute_rank_correlation, axis=1)\n    \n    # Handle cases where all correlations are 0\n    if daily_rank_corrs.std(ddof=0) == 0:\n        return daily_rank_corrs.mean()\n    \n    sharpe_ratio = daily_rank_corrs.mean() / daily_rank_corrs.std(ddof=0)\n    return float(sharpe_ratio)\n\ndef competition_score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str) -> float:\n    if row_id_column_name in solution.columns:\n        del solution[row_id_column_name]\n    if row_id_column_name in submission.columns:\n        del submission[row_id_column_name]\n    \n    # Ensure both dataframes have the same columns\n    common_cols = list(set(solution.columns) & set(submission.columns))\n    solution = solution[common_cols]\n    submission = submission[common_cols]\n    \n    submission = submission.rename(columns={col: col.replace('target_', 'prediction_') for col in submission.columns})\n    solution = solution.replace(SOLUTION_NULL_FILLER, None)\n    \n    # Drop rows where all targets are null\n    valid_rows = ~solution.isnull().all(axis=1)\n    solution = solution[valid_rows]\n    submission = submission[valid_rows]\n    \n    if len(solution) == 0:\n        return 0.0\n    \n    return rank_correlation_sharpe_ratio(pd.concat([solution, submission], axis='columns'))\n\n# Custom scorer for sklearn\ndef sharpe_ratio_scorer(y_true, y_pred):\n    # Create a DataFrame with target columns\n    solution = pd.DataFrame(y_true)\n    solution.columns = [f'target_{i}' for i in range(y_true.shape[1])]\n    \n    # Create submission with same structure\n    submission = pd.DataFrame(y_pred)\n    submission.columns = [f'target_{i}' for i in range(y_pred.shape[1])]\n    \n    # Add row_id for compatibility\n    solution['row_id'] = range(len(solution))\n    submission['row_id'] = range(len(submission))\n    \n    return competition_score(solution, submission, 'row_id')\n\n# Make it a scorer object\ncompetition_scorer = make_scorer(sharpe_ratio_scorer, greater_is_better=True)\n\nprint(\"Evaluation metric functions loaded\")","metadata":{},"outputs":[],"execution_count":null},{"id":"53bfad01-62fd-440f-af26-a92c484fc51c","cell_type":"markdown","source":"### Data Loading and Initial Inspection","metadata":{}},{"id":"60a7db87-07ea-48d8-b70c-a6f227d124f7","cell_type":"code","source":"# Load datasets \ndef load_data():\n    data_path = './' \n    \n    # Load training data\n    train = pd.read_csv(f'{data_path}train.csv')\n    train_labels = pd.read_csv(f'{data_path}train_labels.csv')\n    target_pairs = pd.read_csv(f'{data_path}target_pairs.csv')\n    \n    # Load test data\n    test = pd.read_csv(f'{data_path}test.csv')\n    return train, train_labels, target_pairs, test","metadata":{},"outputs":[],"execution_count":null},{"id":"c0807d1f-b582-4e6c-bb9f-9b3026c573d6","cell_type":"code","source":"# Inspect respective shapes of loaded datasets\ntrain, train_labels, target_pairs, test = load_data()\nprint(f\"\\n Training data shape: {train.shape}\")\nprint(f\" Training labels shape: {train_labels.shape}\")\nprint(f\" Target pairs info: {target_pairs.shape} rows\")\nprint(f\"\\n Test data shape: {test.shape}\")","metadata":{},"outputs":[],"execution_count":null},{"id":"642bd243-ef72-435b-bfb9-79fbf28d5462","cell_type":"code","source":"train.head(3)","metadata":{},"outputs":[],"execution_count":null},{"id":"5fb97611-11a7-4ec5-82ed-1bf2531c03f0","cell_type":"code","source":"train_labels.head(3)","metadata":{},"outputs":[],"execution_count":null},{"id":"e1141f5a-cc2b-40ce-8508-262079e478da","cell_type":"code","source":"target_pairs.head()","metadata":{},"outputs":[],"execution_count":null},{"id":"44985e6e-fe7b-48c7-91ba-364a702aa979","cell_type":"markdown","source":"### Data Cleaning and Preprocessing","metadata":{}},{"id":"913f8c7c-5ac4-4840-a0ed-1a1eceed2700","cell_type":"code","source":"# Define function to clean the train, train_labels, and target_pairs datasets\ndef clean_data(train, train_labels, target_pairs):\n    # Check for missing values\n    print(\"\\n Missing values in train data:\")\n    missing_train = train.isnull().sum()\n    print(missing_train[missing_train > 0])\n    \n    print(\"\\n Missing values in train labels:\")\n    missing_labels = train_labels.isnull().sum()\n    print(missing_labels[missing_labels > 0])\n    \n    # Handle missing values in train data\n    print(\"\\n Handling missing values...\")\n    train_clean = train.copy()\n    \n    # Fill date-related features\n    if 'date' in train_clean.columns:\n        train_clean['date'] = pd.to_datetime(train_clean['date'])\n        train_clean = train_clean.sort_values('date')\n    \n    # Forward fill for time series continuity\n    train_clean = train_clean.fillna(method='ffill')\n    # Then backfill any remaining at the beginning\n    train_clean = train_clean.fillna(method='bfill')\n    \n    # Check for duplicates\n    duplicates = train_clean.duplicated().sum()\n    print(f\"\\n Found {duplicates} duplicate rows - removing...\")\n    train_clean = train_clean.drop_duplicates()\n    \n    # Handle outliers using IQR method\n    print(\"\\n Handling outliers...\")\n    numeric_cols = train_clean.select_dtypes(include=[np.number]).columns\n    train_clean_no_outliers = train_clean.copy()\n    \n    for col in numeric_cols:\n        Q1 = train_clean[col].quantile(0.01)\n        Q3 = train_clean[col].quantile(0.99)\n        IQR = Q3 - Q1\n        lower_bound = Q1 - 1.5 * IQR\n        upper_bound = Q3 + 1.5 * IQR\n        \n        # Count outliers\n        outliers = ((train_clean[col] < lower_bound) | (train_clean[col] > upper_bound)).sum()\n        if outliers > 0:\n            print(f\"  Column '{col}': {outliers} outliers detected\")\n            \n            # Cap outliers instead of removing\n            train_clean_no_outliers[col] = train_clean[col].clip(lower_bound, upper_bound)\n    \n    # Check label data\n    print(\"\\n Label data statistics:\")\n    print(train_labels.describe().T.head())\n    \n    # Verify target pairs\n    print(\"\\n Target pairs info:\")\n    print(f\"Unique asset combinations: {len(target_pairs[['asset1', 'asset2']].drop_duplicates())}\")\n    print(f\"Calculation types: {target_pairs['calculation'].value_counts().to_dict()}\")\n    \n    # Align train and label data\n    if 'date' in train_clean_no_outliers.columns and len(train_clean_no_outliers) == len(train_labels):\n        print(\"\\n Aligning train and label data by date\")\n        \n        # Set the date feature as the indexn\n        train_clean_no_outliers = train_clean_no_outliers.reset_index(drop=True)\n        train_labels = train_labels.reset_index(drop=True)\n    \n    print(\"\\n Data cleaning completed!\")\n    return train_clean_no_outliers, train_labels, target_pairs","metadata":{},"outputs":[],"execution_count":null},{"id":"1bbb1483-033c-415a-b521-39917f1a5a5b","cell_type":"code","source":"# Clean the train, train_labels, and target_pairs datasets\ntrain_clean, train_labels, target_pairs = clean_data(train, train_labels, target_pairs)","metadata":{},"outputs":[],"execution_count":null},{"id":"ce3a0ae2-8a7b-4de5-96c8-a1d546f8f44f","cell_type":"markdown","source":"### Exploratory Data Analysis ","metadata":{}},{"id":"8ed9d416-94e8-48ff-9f38-afcee696f2ea","cell_type":"code","source":"# Define function to perform EDA on train, train_labels, and target_pairs datasets\ndef perform_eda(train, train_labels, target_pairs):\n    # Basic dataset information\n    print(f\"Training features: {train.shape[0]} samples, {train.shape[1]} features\")\n    print(f\"Training labels: {train_labels.shape[0]} samples, {train_labels.shape[1]} targets\")\n    \n    # Feature distributions\n    print(\"\\n Numeric Features Distributions\")\n    numeric_cols = train.select_dtypes(include=[np.number]).columns[:5]\n    plt.figure(figsize=(15, 10))\n    for i, col in enumerate(numeric_cols, 1):\n        plt.subplot(2, 3, i)\n        sns.histplot(train[col], kde=True)\n        plt.title(f'Distribution of {col}')\n    plt.tight_layout()\n    plt.show()\n    \n    # Perform correlation analysis\n    print(\"\\n Compute feature correlations\")\n    # Sample a subset to plot a correlation matrix\n    sample_size = min(1000, len(train))\n    sample_train = train.sample(sample_size, random_state=42)\n    \n    # Select top 10 numeric features \n    numeric_cols = sample_train.select_dtypes(include=[np.number]).columns[:10]\n    corr_matrix = sample_train[numeric_cols].corr()\n    plt.figure(figsize=(12, 10))\n    sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap='coolwarm')\n    plt.title('Feature Correlation Matrix (First 10 Features)')\n    plt.tight_layout()\n    plt.show()\n    \n    # Analyze Target variables\n    print(\"\\n Analyze target variables\")\n    # Sample targets for visualization\n    sample_targets = train_labels.sample(sample_size, random_state=42)\n    \n    # Plot distribution of first 5 targets\n    plt.figure(figsize=(15, 10))\n    for i in range(5):\n        if i < sample_targets.shape[1]: \n            plt.subplot(2, 3, i+1)\n            sns.histplot(sample_targets[f'target_{i}'], kde=True)\n            plt.title(f'Distribution of target_{i}')\n    plt.tight_layout()\n    plt.show()\n    \n    # Perform Time series analysis \n    if 'date' in train.columns:\n        print(\"\\n Performing time series analysis...\")\n        train_with_date = train.copy()\n        train_with_date['date'] = pd.to_datetime(train_with_date['date'])\n        train_with_date = train_with_date.set_index('date')\n        \n        plt.figure(figsize=(14, 10))\n        for i, col in enumerate(numeric_cols[:3], 1):\n            plt.subplot(3, 1, i)\n            plt.plot(train_with_date.index, train_with_date[col])\n            plt.title(f'Time Series: {col}')\n            plt.tight_layout()\n        plt.show()\n    \n    # \\perform Target Pair Analysis\n    print(\"\\n Analyze target pairs\")\n    plt.figure(figsize=(10, 6))\n    target_pairs['asset1'].value_counts().plot(kind='bar')\n    plt.title('Distribution of Asset 1 in Target Pairs')\n    plt.tight_layout()\n    plt.show()\n    \n    # Compute and display the competition metric on a random prediction\n    print(\"\\n Calculate baseline competition metric for random predictions)\")\n    random_preds = np.random.randn(len(train_labels), train_labels.shape[1])\n    solution_df = train_labels.copy()\n    submission_df = pd.DataFrame(random_preds, columns=train_labels.columns)\n    \n    # Add row_id for the metric function\n    solution_df['row_id'] = range(len(solution_df))\n    submission_df['row_id'] = range(len(submission_df))\n    baseline_score = competition_score(solution_df, submission_df, 'row_id')\n    print(f\"Baseline random prediction score (Sharpe ratio): {baseline_score:.4f}\")\n\n","metadata":{},"outputs":[],"execution_count":null},{"id":"7c8a304e-e2cf-4d13-afc2-c0f28574b63f","cell_type":"code","source":"# Perform EDA on cleaned train, train_labels, and target_pairs datasets\nperform_eda(train_clean, train_labels, target_pairs)","metadata":{},"outputs":[],"execution_count":null},{"id":"2feb5728-059e-4b33-b6f0-0485bb77c12b","cell_type":"markdown","source":"### Feature Engineering","metadata":{}},{"id":"3b5835c1-03f0-49ee-abc0-6c2a846be902","cell_type":"code","source":"# Define function to perform feature engineering\ndef feature_engineering(train, train_labels):\n    train_eng = train.copy()\n    \n    # Date-based features (if date column exists)\n    if 'date' in train_eng.columns:\n        print(\"Create date-based features\")\n        train_eng['date'] = pd.to_datetime(train_eng['date'])\n        train_eng['day_of_week'] = train_eng['date'].dt.dayofweek\n        train_eng['month'] = train_eng['date'].dt.month\n        train_eng['quarter'] = train_eng['date'].dt.quarter\n        train_eng['is_weekend'] = train_eng['day_of_week'].isin([5, 6]).astype(int)\n        \n        # Drop the original date column\n        train_eng = train_eng.drop('date', axis=1)\n    \n    # Technical indicators for numeric features\n    print(\" Create technical indicators\")\n    numeric_cols = train_eng.select_dtypes(include=[np.number]).columns\n    \n    # Moving averages for key features\n    for col in numeric_cols[:10]:  # Just a subset to avoid too many features\n        train_eng[f'{col}_ma_5'] = train_eng[col].rolling(window=5, min_periods=1).mean()\n        train_eng[f'{col}_ma_20'] = train_eng[col].rolling(window=20, min_periods=1).mean()\n        train_eng[f'{col}_vol_20'] = train_eng[col].rolling(window=20, min_periods=1).std()\n        train_eng[f'{col}_mom_10'] = train_eng[col].diff(10)\n    \n    # Cross-feature interactions\n    print(\" Create cross-feature interactions\")\n    # Only for the most important features (to avoid explosion of features)\n    for i in range(min(5, len(numeric_cols))):\n        for j in range(i+1, min(8, len(numeric_cols))):\n            col1, col2 = numeric_cols[i], numeric_cols[j]\n            train_eng[f'{col1}_x_{col2}'] = train_eng[col1] * train_eng[col2]\n            train_eng[f'{col1}_{col2}_ratio'] = train_eng[col1] / (train_eng[col2] + 1e-8)  # Avoid division by zero\n    \n    # Rank normalization for all numeric features\n    print(\" Apply rank normalization to numeric features\")\n    for col in numeric_cols:\n        train_eng[col] = train_eng[col].rank(pct=True)\n    \n    # Handle any remaining NaNs after feature engineering\n    train_eng = train_eng.fillna(0.5)  # Impute NaNs with median rank\n    \n    print(f\" New shape: {train_eng.shape}\")\n    return train_eng","metadata":{},"outputs":[],"execution_count":null},{"id":"245a37cf-f8bd-48b9-9157-0ad1f3eadfa8","cell_type":"code","source":"# Perform perform feature engineering train_clean and train_labels\ntrain_eng = feature_engineering(train_clean, train_labels)","metadata":{},"outputs":[],"execution_count":null},{"id":"2e8f1db7-5be3-41be-a030-fb2ed798ba64","cell_type":"markdown","source":"### Data Prepration","metadata":{}},{"id":"ec1be4d0-e420-415f-b024-8d709d220fe4","cell_type":"code","source":"# Define function to prepare data for modelling based on a time-based split\ndef prepare_model_data(train_eng, train_labels):  \n    # Convert to numpy arrays for XGBoost\n    X = train_eng.select_dtypes(include=[np.number]).values\n    y = train_labels.values\n    print(f\"Final feature matrix shape: {X.shape}\")\n    print(f\"Target matrix shape: {y.shape}\")\n    \n    # Perform Train-Test split\n    split_idx = int(0.8 * len(X))\n    X_train, X_val = X[:split_idx], X[split_idx:]\n    y_train, y_val = y[:split_idx], y[split_idx:]\n    print(f\"Training set: {X_train.shape[0]} samples\")\n    print(f\"Validation set: {X_val.shape[0]} samples\")\n    \n    return X_train, X_val, y_train, y_val","metadata":{},"outputs":[],"execution_count":null},{"id":"9f144c5a-6a86-4f74-ab70-127a3b0f55ca","cell_type":"code","source":"# Prepare data for modelling\nX_train, X_val, y_train, y_val = prepare_model_data(train_eng, train_labels)","metadata":{},"outputs":[],"execution_count":null},{"id":"058d4708-b509-4cf4-9e9b-a4c7cde3646a","cell_type":"markdown","source":"### Modelling","metadata":{}},{"id":"fe316a3c-30ee-4fe1-bcf6-202284e22fc4","cell_type":"code","source":"# Train a baseline XGBoost model\ndef create_xgboost_model(gpu_available=False):   \n    # Define Base parameters\n    params = {\n        'objective': 'reg:squarederror',\n        'eval_metric': 'rmse',\n        'eta': 0.1,\n        'max_depth': 6,\n        'subsample': 0.8,\n        'colsample_bytree': 0.8,\n        'tree_method': 'gpu_hist' if gpu_available else 'auto',\n        'random_state': 42,\n        'n_estimators': 100\n    }\n    \n    print(f\" XGBoost parameters: {params}\")\n    \n    # Create the model\n    model = xgb.XGBRegressor(**params)\n    return model, params\n\n# Create and train the model\ndef train_baseline_model(model, X_train, y_train, X_val, y_val):  \n    # Train the model\n    start_time = time.time()\n    \n    model.fit(\n        X_train, y_train,\n        eval_set=[(X_val, y_val)],\n        early_stopping_rounds=20,\n        verbose=10\n    )\n    \n    train_time = time.time() - start_time\n    print(f\" Baseline Vanilla XGBoost model training time: {train_time:.2f} seconds\")\n    \n    # Make predictions\n    val_preds = model.predict(X_val)\n    \n    # Calculate competition metric\n    val_solution = pd.DataFrame(y_val, columns=[f'target_{i}' for i in range(y_val.shape[1])])\n    val_submission = pd.DataFrame(val_preds, columns=[f'target_{i}' for i in range(y_val.shape[1])])\n    \n    # Add row_id for metric calculation\n    val_solution['row_id'] = range(len(val_solution))\n    val_submission['row_id'] = range(len(val_submission))\n    \n    score_val = competition_score(val_solution, val_submission, 'row_id')\n    print(f\" Baseline Vanilla XGBoost model validation score (Sharpe ratio): {score_val:.4f}\")\n    \n    # Compute and visualize feature importance (top-20 features)\n    if hasattr(model, 'feature_importances_'):\n        plt.figure(figsize=(12, 8))\n        feat_importances = pd.Series(model.feature_importances_, index=train_eng.columns)\n        feat_importances.nlargest(20).plot(kind='barh')\n        plt.title('Top 20 Feature Importances')\n        plt.tight_layout()\n        plt.show()\n    \n    return model, val_preds, score_val\n\n","metadata":{},"outputs":[],"execution_count":null},{"id":"a25a7f8c-8940-40d0-b0fc-f28302d35d7b","cell_type":"code","source":"# Create baseline vanilla XGBoost model\nmodel, base_params = create_xgboost_model(GPU_AVAILABLE)","metadata":{},"outputs":[],"execution_count":null},{"id":"6974085f-12d0-4b2b-8d5a-1d44d3c091d1","cell_type":"code","source":"# Train baseline vanilla XGBoost model\nmodel, val_preds, baseline_score = train_baseline_model(model, X_train, y_train, X_val, y_val)","metadata":{},"outputs":[],"execution_count":null},{"id":"ef1a3cbe-9db7-4acd-911f-0c14211ae3ea","cell_type":"markdown","source":"#### Hyperparameter Optimization\n- Define function to optimize the baseline vanilla XGBoost model using RandomSearchCV.","metadata":{}},{"id":"97c4ee75-e993-40ca-abb7-c48eb9f9439c","cell_type":"code","source":"def optimize_model(X_train, y_train, X_val, y_val, gpu_available=False):  \n    # Define parameter grid\n    param_dist = {\n        'n_estimators': [100, 200, 300, 500],\n        'max_depth': [3, 5, 7, 9, 11],\n        'learning_rate': [0.01, 0.05, 0.1, 0.2],\n        'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],\n        'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0],\n        'gamma': [0, 0.1, 0.2, 0.3, 0.4],\n        'min_child_weight': [1, 3, 5, 7],\n        'reg_alpha': [0, 0.1, 0.5, 1.0],\n        'reg_lambda': [0.5, 1.0, 1.5, 2.0]\n    }\n    \n    # Set device\n    if gpu_available:\n        param_dist['tree_method'] = ['gpu_hist']\n    else:\n        param_dist['tree_method'] = ['auto']\n    \n    print(\"Starting RandomizedSearchCV...\")\n    print(f\"Parameter grid size: {np.prod([len(v) for v in param_dist.values()])} combinations\")\n    print(f\"Sampling 20 parameter combinations\")\n    \n    # Perform a Time series split for validation\n    tscv = TimeSeriesSplit(n_splits=3)\n    \n    # Create base model\n    base_model = xgb.XGBRegressor(\n        objective='reg:squarederror',\n        random_state=42\n    )\n    \n    # RandomizedSearchCV\n    random_search = RandomizedSearchCV(\n        estimator=base_model,\n        param_distributions=param_dist,\n        n_iter=20,  \n        scoring=competition_scorer,\n        cv=tscv,\n        verbose=2,\n        random_state=42,\n        n_jobs=-1\n    )\n    \n    # Fit RandomizedSearchCV\n    start_time = time.time()\n    random_search.fit(X_train, y_train)\n    search_time = time.time() - start_time\n    \n    print(f\"\\nRandomizedSearchCV optimization time: {search_time:.2f} seconds\")\n    print(f\"Best parameters: {random_search.best_params_}\")\n    print(f\"Best cross-validated score: {random_search.best_score_:.4f}\")\n    \n    # Train the best param model on training set\n    best_params = random_search.best_params_\n    best_model = xgb.XGBRegressor(**best_params, objective='reg:squarederror')\n    \n    best_model.fit(\n        X_train, y_train,\n        eval_set=[(X_val, y_val)],\n        early_stopping_rounds=20,\n        verbose=10\n    )\n    \n    # Evaluate optimized XGBoost model on validation set\n    val_preds = best_model.predict(X_val)\n    val_solution = pd.DataFrame(y_val, columns=[f'target_{i}' for i in range(y_val.shape[1])])\n    val_submission = pd.DataFrame(val_preds, columns=[f'target_{i}' for i in range(y_val.shape[1])])\n    val_solution['row_id'] = range(len(val_solution))\n    val_submission['row_id'] = range(len(val_submission))\n    \n    optimized_score = competition_score(val_solution, val_submission, 'row_id')\n    print(f\" Optimized XGBoost model validation score (Sharpe ratio): {optimized_score:.4f}\")\n    print(f\" Improvement over baseline: {(optimized_score - baseline_score) / abs(baseline_score) * 100:.2f}%\")\n    \n    return best_model, best_params, optimized_score","metadata":{},"outputs":[],"execution_count":null},{"id":"37221604-1722-4079-9fe5-009a72fc9230","cell_type":"markdown","source":"### XGBoost Model Evaluation and Inference Setup","metadata":{}},{"id":"1881b2ba-8519-4564-adb8-14926726a87e","cell_type":"code","source":"# Final model evaluation\nprint(\"\\n RandomSearchCV optimized XGBoost Model Evaluation\")\nprint(f\"Baseline model score: {baseline_score:.4f}\")\nprint(f\"Optimized model score: {optimized_score:.4f}\")\n\n# Save optimized model\nmodel_filename = 'commodity_prediction_model.pkl'\njoblib.dump(best_model, model_filename)\nprint(f\"\\n Model saved to {model_filename}\")","metadata":{},"outputs":[],"execution_count":null},{"id":"f0a66c78-147a-4440-96e4-8670bc3b882d","cell_type":"code","source":"import os\nimport time\nimport joblib\nimport numpy as np\nimport pandas as pd\nimport polars as pl\nimport xgboost as xgb\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport kaggle_evaluation.mitsui_inference_server\n\nNUM_TARGET_COLUMNS = 424\n\nmodel = None\n\ndef predict(\n    test: pl.DataFrame,\n    label_lags_1_batch: pl.DataFrame,\n    label_lags_2_batch: pl.DataFrame,\n    label_lags_3_batch: pl.DataFrame,\n    label_lags_4_batch: pl.DataFrame,\n) -> pd.DataFrame:\n\n    global model\n    if model is None:\n        start_time = time.time()\n        print(\" Loading model for first prediction...\")\n        \n        model_path = 'commodity_prediction_model.pkl'\n\n    # Convert Polars DataFrame to Pandas for processing\n    test_pd = test.to_pandas()\n    \n    # Perform feature engineering on test set\n    # Engineer date-based features\n    if 'date' in test_pd.columns:\n        test_pd['date'] = pd.to_datetime(test_pd['date'])\n        test_pd['day_of_week'] = test_pd['date'].dt.dayofweek\n        test_pd['month'] = test_pd['date'].dt.month\n        test_pd['quarter'] = test_pd['date'].dt.quarter\n        test_pd['is_weekend'] = test_pd['day_of_week'].isin([5, 6]).astype(int)\n        test_pd = test_pd.drop('date', axis=1)\n    \n    # Engineer rank normalization for numeric features\n    numeric_cols = test_pd.select_dtypes(include=[np.number]).columns\n    for col in numeric_cols:\n        # Rank and convert to percentile\n        test_pd[col] = test_pd[col].rank(pct=True).fillna(0.5)\n    \n    # Handle any remaining NaNs\n    test_pd = test_pd.fillna(0.5)\n    \n    # Make prediction (one row per batch in the API)\n    try:\n        prediction = model.predict(test_pd)[0]\n    except Exception as e:\n        print(f\"⚠️ Prediction error: {str(e)} - using zeros\")\n        prediction = np.zeros(NUM_TARGET_COLUMNS)\n    \n    # Format output as Pandas DataFrame \n    predictions = pd.DataFrame({\n        f'target_{i}': [float(prediction[i])] for i in range(NUM_TARGET_COLUMNS)\n    })\n    \n    # Verify output \n    assert isinstance(predictions, pd.DataFrame), \"Output must be a Pandas DataFrame\"\n    assert len(predictions) == 1, \"Output must contain exactly one row\"\n    assert predictions.shape[1] == NUM_TARGET_COLUMNS, f\"Output must have {NUM_TARGET_COLUMNS} columns\"\n    \n    return predictions","metadata":{},"outputs":[],"execution_count":null},{"id":"9b139a36-af00-4d46-93e2-76f59b47beeb","cell_type":"markdown","source":"### Submission","metadata":{}},{"id":"ab63d0ca-88d7-48fd-85f0-ce5ab91839dd","cell_type":"code","source":"import kaggle_evaluation.mitsui_inference_server\n\n# Instantiate inference server\ninference_server = kaggle_evaluation.mitsui_inference_server.MitsuiInferenceServer(predict)\n\nif os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n    inference_server.serve()\nelse:\n    inference_server.run_local_gateway(('/kaggle/input/mitsui-commodity-prediction-challenge/',))","metadata":{},"outputs":[],"execution_count":null}]}